{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mellotroninferencecolab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak9250/mellotron/blob/master/Mellotroninferencecolab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrzsRRosWy4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/mellotron.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rArnxfDCXCkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd mellotron/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FruCVcEyXLhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UqfrlwmX6j1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d3qUcH2Y2Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1Rm5rV5XaWWiUbIpg5385l5sh68z2bVOE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N7vOVAcYTS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install vamp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzabK43Cotsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboard==1.14.0 tensorboardX==1.8 tensorflow-gpu==1.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MpgZGp7PbGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdRlI-57YCJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.io.wavfile import write\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from waveglow.denoiser import Denoiser\n",
        "from layers import TacotronSTFT\n",
        "from train import load_model\n",
        "from data_utils import TextMelLoader, TextMelCollate\n",
        "from text import cmudict, text_to_sequence\n",
        "from mellotron_utils import get_data_from_musicxml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o08e5pBHasqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def panner(signal, angle):\n",
        "    angle = np.radians(angle)\n",
        "    left = np.sqrt(2)/2.0 * (np.cos(angle) - np.sin(angle)) * signal\n",
        "    right = np.sqrt(2)/2.0 * (np.cos(angle) + np.sin(angle)) * signal\n",
        "    return np.dstack((left, right))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BlvAC4oas_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_mel_f0_alignment(mel_source, mel_outputs_postnet, f0s, alignments, figsize=(16, 16)):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    axes[0].imshow(mel_source, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[1].imshow(mel_outputs_postnet, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[2].scatter(range(len(f0s)), f0s, alpha=0.5, color='red', marker='.', s=1)\n",
        "    axes[2].set_xlim(0, len(f0s))\n",
        "    axes[3].imshow(alignments, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[0].set_title(\"Source Mel\")\n",
        "    axes[1].set_title(\"Predicted Mel\")\n",
        "    axes[2].set_title(\"Source pitch contour\")\n",
        "    axes[3].set_title(\"Source rhythm\")\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Weg_ThZdavB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mel(path):\n",
        "    audio, sampling_rate = librosa.core.load(path, sr=hparams.sampling_rate)\n",
        "    audio = torch.from_numpy(audio)\n",
        "    if sampling_rate != hparams.sampling_rate:\n",
        "        raise ValueError(\"{} SR doesn't match target {} SR\".format(\n",
        "            sampling_rate, stft.sampling_rate))\n",
        "    audio_norm = audio / hparams.max_wav_value\n",
        "    audio_norm = audio_norm.unsqueeze(0)\n",
        "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "    melspec = stft.mel_spectrogram(audio_norm)\n",
        "    melspec = melspec.cuda()\n",
        "    return melspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IjYmVPlawvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = create_hparams()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpGpHTiLa05M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stft = TacotronSTFT(hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
        "                    hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
        "                    hparams.mel_fmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMmlShrrn-IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO2K5-BXoO54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1ZesPPyRRKloltRIuRnGZ2LIUEuMSVjkI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_v_FlqGn_23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv mellotron_libritts.pt models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dHU6gf3eXIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv waveglow_256channels_v4.pt models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzXa-65Na3MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"models/mellotron_libritts.pt\"\n",
        "tacotron = load_model(hparams).cuda().eval()\n",
        "tacotron.load_state_dict(torch.load(checkpoint_path)['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWRwNiodn7FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waveglow_path = 'models/waveglow_256channels_v4.pt'\n",
        "waveglow = torch.load(waveglow_path)['model'].cuda().eval()\n",
        "denoiser = Denoiser(waveglow).cuda().eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufHLQHJAeofU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arpabet_dict = cmudict.CMUDict('data/cmu_dictionary')\n",
        "audio_paths = 'data/examples_filelist.txt'\n",
        "dataloader = TextMelLoader(audio_paths, hparams)\n",
        "datacollate = TextMelCollate(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPu9wXNBesmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_idx = 0\n",
        "audio_path, text, sid = dataloader.audiopaths_and_text[file_idx]\n",
        "\n",
        "# get audio path, encoded text, pitch contour and mel for gst\n",
        "text_encoded = torch.LongTensor(text_to_sequence(text, hparams.text_cleaners, arpabet_dict))[None, :].cuda()    \n",
        "pitch_contour = dataloader[file_idx][3][None].cuda()\n",
        "mel = load_mel(audio_path)\n",
        "print(audio_path, text)\n",
        "\n",
        "# load source data to obtain rhythm using tacotron 2 as a forced aligner\n",
        "x, y = tacotron.parse_batch(datacollate([dataloader[file_idx]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVLeZs8HevkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ipd.Audio(audio_path, rate=hparams.sampling_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1yQysmreygC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speaker_ids = TextMelLoader(\"filelists/libritts_train_clean_100_audiopath_text_sid_atleast5min_val_filelist.txt\", hparams).speaker_ids\n",
        "speakers = pd.read_csv('filelists/libritts_speakerinfo.txt', engine='python',header=None, comment=';', sep=' *\\| *', \n",
        "                       names=['ID', 'SEX', 'SUBSET', 'MINUTES', 'NAME'])\n",
        "speakers['MELLOTRON_ID'] = speakers['ID'].apply(lambda x: speaker_ids[x] if x in speaker_ids else -1)\n",
        "female_speakers = cycle(\n",
        "    speakers.query(\"SEX == 'F' and MINUTES > 20 and MELLOTRON_ID >= 0\")['MELLOTRON_ID'].sample(frac=1).tolist())\n",
        "male_speakers = cycle(\n",
        "    speakers.query(\"SEX == 'M' and MINUTES > 20 and MELLOTRON_ID >= 0\")['MELLOTRON_ID'].sample(frac=1).tolist())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQYOih1ye5U6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    # get rhythm (alignment map) using tacotron 2\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, rhythm = tacotron.forward(x)\n",
        "    rhythm = rhythm.permute(1, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk73dUyFe8MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speaker_id = next(female_speakers) if np.random.randint(2) else next(male_speakers)\n",
        "speaker_id = torch.LongTensor([speaker_id]).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, _ = tacotron.inference_noattention(\n",
        "        (text_encoded, mel, speaker_id, pitch_contour, rhythm))\n",
        "\n",
        "plot_mel_f0_alignment(x[2].data.cpu().numpy()[0],\n",
        "                      mel_outputs_postnet.data.cpu().numpy()[0],\n",
        "                      pitch_contour.data.cpu().numpy()[0, 0],\n",
        "                      rhythm.data.cpu().numpy()[:, 0].T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csOAjbT3e-6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[:, 0]\n",
        "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NnaY5fdfDFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = get_data_from_musicxml('data/haendel_hallelujah.musicxml', 132, convert_stress=True)\n",
        "panning = {'Soprano': [-60, -30], 'Alto': [-40, -10], 'Tenor': [30, 60], 'Bass': [10, 40]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4d7S9dMfIog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_speakers_per_part = 4\n",
        "frequency_scaling = 0.4\n",
        "n_seconds = 90\n",
        "audio_stereo = np.zeros((hparams.sampling_rate*n_seconds, 2), dtype=np.float32)\n",
        "for i, (part, v) in enumerate(data.items()):\n",
        "    rhythm = data[part]['rhythm'].cuda()\n",
        "    pitch_contour = data[part]['pitch_contour'].cuda()\n",
        "    text_encoded = data[part]['text_encoded'].cuda()\n",
        "    \n",
        "    for k in range(n_speakers_per_part):\n",
        "        pan = np.random.randint(panning[part][0], panning[part][1])\n",
        "        if any(x in part.lower() for x in ('soprano', 'alto', 'female')):\n",
        "            speaker_id = torch.LongTensor([next(female_speakers)]).cuda()\n",
        "        else:\n",
        "            speaker_id = torch.LongTensor([next(male_speakers)]).cuda()\n",
        "        print(\"{} MellotronID {} pan {}\".format(part, speaker_id.item(), pan))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            mel_outputs, mel_outputs_postnet, gate_outputs, alignments_transfer = tacotron.inference_noattention(\n",
        "                (text_encoded, mel, speaker_id, pitch_contour*frequency_scaling, rhythm))\n",
        "\n",
        "            audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[0, 0]\n",
        "            audio = audio.cpu().numpy()\n",
        "            audio = panner(audio, pan)\n",
        "            audio_stereo[:audio.shape[0]] += audio            \n",
        "            write(\"{} {}.wav\".format(part, speaker_id.item()), hparams.sampling_rate, audio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1cQqqETfLyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_stereo = audio_stereo / np.max(np.abs(audio_stereo))\n",
        "write(\"audio_stereo.wav\", hparams.sampling_rate, audio_stereo)\n",
        "ipd.Audio([audio_stereo[:,0], audio_stereo[:,1]], rate=hparams.sampling_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bjwVWWUhpm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}